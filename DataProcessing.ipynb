{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARROW Python Activity 5.2 and 5.3 Hints, Tips, and Code Snippets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains hints, tips and code snippets that you might find useful in completing Activities 5.2 and 5.3\n",
    "\n",
    "Generally, many scientific data processing tasks will require a very similar workflow. Something like:\n",
    "\n",
    "1. Read in some data.\n",
    "2. Process the data.\n",
    "3. Optionally, Display the data.\n",
    "4. Write out the data - usually to a new file.\n",
    "\n",
    "> **OPTIONAL:** For those of you who are more confident in Python coding, you could embed code that performs all the workflow steps inside a loop. You could then work out how to provide the program with a list of all your spectrum file names and process all of them in one go. If you do attempt this, don't use _Matplotlib_ to display anything. Use _Bokeh_ instead. For a number of technical reasons, _Matplotlib_ doesn't display multiple, sequential plots very well in Jupyter notebooks.\n",
    "\n",
    "> **HINT:** We'll want to preserve the original header information from our file so that we can add it to our output file after we have processed the non-header data. You'll need to read in the spectrum header lines (there's 12 of them - all starting with '#') using ordinary _Python_ File I/O. Later, you'll use ordinary File I/O again to write the saved header to a new file then **append** the data in the modified _Pandas_ `DataFrame` as comma delimited data. Use the _Pandas_ **`.to_csv()`** method with `mode='a'`. \n",
    "> You'll want to remember this procedure for later on during this Topic.\n",
    "\n",
    "> **HINT:** Use _Pandas_ to read in, process and write out the main spectral data.\n",
    "\n",
    "> **HINT:** You can display the spectrum using either _Matplotlib_ or _Bokeh_. _Matplotlib_ may seem easier to make quick plots, but _Bokeh_ will be much more useful later on.\n",
    "\n",
    "> **HINT:** Review the `UsingPandas`, `UsingBokeh` and `FileIO` notebooks before you start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0 - Imports and Functions\n",
    "\n",
    "Import the modules and packages you'll need. You should be pretty confident with this now. We'll do the first obvious one, but the rest are up to you!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Any others you might need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now write any functions you might find useful later. This isn't strictly necessary, but it is good programming proceedure and will prove especially useful if you put the simple code into a loop later.\n",
    "\n",
    "To get you started, we'll provide you with a function that performs the slightly awkward two-part process of reading in the data file\n",
    "\n",
    "1. Reading (and saving for later) the header lines.\n",
    "2. Reading the actual data. \n",
    "\n",
    "You could, of course just do this in a block at the start of the code without defining a reuseable function.\n",
    "\n",
    "> We strongly recommend that you do at least try and understand what the function code is doing!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ARROW_data(filename):\n",
    "    \"\"\"Reads in and partially processes an  ARROW spectrum\n",
    "    \n",
    "    The spectrum file contains a number of header lines indicated by `#' or blanks. \n",
    "    This function splits these from the main data and returns both \n",
    "            \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        Name of the spectrum file\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dat : class: pandas.DataFrame\n",
    "        Spectrum data\n",
    "    Header lines : list of str\n",
    "        List of header lines\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read lines till first line not starting with #, or whitespace.\n",
    "    # Store these as a list\n",
    "    header_list=[]\n",
    "    number_header_lines=0\n",
    "    dat=None\n",
    "    with open(filename) as f:\n",
    "        line = f.readline()\n",
    "        while line[0] == '#' or line[0] == ',' or line[0].isspace():\n",
    "            header_list.append(line)\n",
    "            number_header_lines += 1\n",
    "            line = f.readline()\n",
    "        dat = pd.read_csv(filename, header=number_header_lines)\n",
    "\n",
    "    return dat, header_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's write a function to convert from observed frequency to radial velocity. \n",
    "\n",
    "> **Note:** You'll need to complete the code in the next cell to make it work properly. Just need to fill add code to perform the actual conversion where instructed.\n",
    "\n",
    "> **NOTE:** If you pass a _Pandas_ `Series` (or _NumPy_ `array`) to the function it will operate on all elements in the input data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert frequency to radial velocity. Normally expect this to be pleaced at the\n",
    "# start of the program\n",
    "\n",
    "def freq_to_vel(freq, f0=1420.4e6):\n",
    "    ''' Takes a frequency value (or Pandas Dataframe column or Series) and returns\n",
    "    a velocity value (or new Dataframe column of values). f0 is the rest\n",
    "    frequency and defaults to 1420.4 MHz'''\n",
    "    \n",
    "    # We need a value for 'c' - speed of light. Either just do it here or, neatly, use the \n",
    "    # astropy 'constants'\n",
    "    c = 299792458.0  #m/s\n",
    "    \n",
    "    #\n",
    "    #v = # DO YOUR CALCULATION HERE - probably use km/s for convenience \n",
    "    #\n",
    "    \n",
    "    return v  #(km/s)                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Get the data\n",
    "\n",
    "With our helper functions defined, we're now ready to start writing the actual analysis program.\n",
    "\n",
    "First we'll use our function to read in the header lines and the main data.\n",
    "\n",
    "> **Note:** You'll need to complete the code in the next cell to make it work properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "      <th>intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-800000</td>\n",
       "      <td>2.322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-795000</td>\n",
       "      <td>2.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-790000</td>\n",
       "      <td>2.439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-785000</td>\n",
       "      <td>2.446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   frequency  intensity\n",
       "0    -800000      2.322\n",
       "1    -795000      2.363\n",
       "2    -790000      2.439\n",
       "3    -785000      2.446"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt the user for a file name (we'll call it file_name)\n",
    "# You should know how to do this by now\n",
    "file_name = #?????????\n",
    "\n",
    "spectrum_df, header_lines = read_ARROW_data(# What goes in here?)\n",
    "\n",
    "# Display the first few lines - does it look reasonable?\n",
    "spectrum_df.head(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Baseline Removal\n",
    "\n",
    "This activity uses the \"_off-source_\" spectra you should have collected.\n",
    "\n",
    "You'll need to read these in, find an average of the `intensity` column (the values in the `frequency` column will be the same as those in the main spectrum files, so you don't need to modify them).\n",
    "\n",
    "The analysis will require the following steps:\n",
    "\n",
    "1. Read in the separate background files using _Pandas_. We can use the same function as before, but you can ignore the header lines completely.\n",
    "2. Compute the average of the `intensity` columns. Take advantage of the fact that, as with a _NumPy_ 1D `array`, you can sum the corresponding elements of several of _Pandas_ `Series` (or `DataFrame` columns) by just using the `+` operator. Similarly, you can divide all elements in a column by a number by just using `/`. See Section 5.3 (_NumPy Arrays_), in the \"_Python - What you need to know_\" resource.\n",
    "3. Subtract this average off-source `intensity` from the main spectrum's `intensity` column.\n",
    "\n",
    "To read in the data, you could use our data reading function or just skip the header lines using the _Pandas_ **`read_csv()`** function.\n",
    "\n",
    "Below is a very rudimentary way of reading several separate files this using \"_hard coded_\" file names. You should be able to make this more flexible by providing a list of file names (which could generated by reading the names from a text file you supply) and iterating or looping over this list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the background spectra, average and subtract from the spectrum\n",
    "# Here we use  'hard-wired' file names but you could use a file list, or manually enter them\n",
    "number_header_lines = 12\n",
    "\n",
    "bg1 = pd.read_csv('bg1.csv', header=number_header_lines)\n",
    "bg2 = pd.read_csv('bg2.csv', header=number_header_lines)\n",
    "bg3 = pd.read_csv('bg3.csv', header=number_header_lines)\n",
    "\n",
    "# Compute average 'intensity' values\n",
    "bg_av = (bg1['intensity']+bg2['intensity']+bg3['intensity'])/3\n",
    "print(type(bg_av))\n",
    "# Subract from spectrum 'intensity'\n",
    "spectrum_df['intensity'] = spectrum_df['intensity']-bg_av.values\n",
    "\n",
    "spectrum_df.head(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you did want to try a more efficient data loading approach, you should probably implement steps similar to the following:\n",
    "1. Prepare a text file (with a simple text editor - NOT a word processor) containing a list of background files - one file name per line. \n",
    "2. After opening the text file, use the **`.read().splitlines()`** method demonstrated in the section 2.2 of the `FileIO` notebook to produce a Python list of these file names.\n",
    "3. Now produce a _Python_ list of the actual data from each of these files. Here's a code snippet that would perform steps 2 and 3:\n",
    "\n",
    "```python\n",
    "li=[]\n",
    "    for f in bg_files:\n",
    "        df = pd.read_csv(f, header=12)\n",
    "        li.append(df)\n",
    "```\n",
    "\n",
    "4. Now you have a list contaning data you can produce an average set of data by using the **`sum()`** function and then dividing by the number of files - which, of course, is the length of the file list you've produced.\n",
    "\n",
    "```python\n",
    "bg_av = sum(li)/len(li)\n",
    "```\n",
    "5. Finally you can subtract the `intensity` values of this from the `spectrum_df` `intensity` data as explained above.\n",
    "\n",
    "```python\n",
    "spectrum_df['intensity'] = spectrum_df['intensity']-bg_av['intensity'].values\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Process the data\n",
    "\n",
    "Thankfully we've defined our **`freq_to_vel()`** function, so this step is now pretty trivial.\n",
    "\n",
    "After processing the data, there's another step you'll need to perform to add the newly computed velocity column to the existing `DataFrame`. This modification isn't necessary if you're going to be using straightforward _Python_ File IO to write the data, but doing so makes writing the file later using _Pandas_ pretty easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert frequency to radial velocity values using this function\n",
    "spectrum_v = freq_to_vel(spectrum_df['frequency'])\n",
    "\n",
    "# Add a new 'velocity' column with these values\n",
    "spectrum_df['velocity'] = spectrum_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Display the processed data\n",
    "\n",
    "You can use _Matplotlib_ or _Bokeh_. If you need help, consult the `UsingMatplotlib` and `UsingBokeh` notebooks for more information.\n",
    "\n",
    "Don't forget you need to extract the _x_ values and _y_ values from your data to pass to _Matplotlib_ or _Bokeh_. Section 2 of the `UsingBokeh` notebook should be helpful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Finally, write the modified data out to a file.\n",
    "\n",
    "We'll leave most of this section for you to complete. Your code should perform the following operations.\n",
    "\n",
    "1. Prompt the user for a new file name.\n",
    "2. Use the **`.writelines()`** function described in section 2.1 of the `FileIO` notebook to write the saved header lines to this file.\n",
    "3. Now **append** the modified _Pandas_ data using the _Pandas_ **`.to_csv()`** method that is illustrated in section 3 of the `UsingPandas` notebook. Don't forget to **append** the data or you will overwrite the header lines.\n",
    "\n",
    "> **Note:** You'll need to complete the code in the next cell to make it work properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for a new file name\n",
    "new_file_name = #########?\n",
    "\n",
    "# First write the header lines that we read in earlier to the file.\n",
    "# Use the .writelines() function from FileIO section 2.1\n",
    "\n",
    "    \n",
    "# Now APPEND the modified csv data using the pandas .to_csv() method \n",
    "# UsingPandas section 3 should help"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
